{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7270c7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from E:\\Supply Chain Data Integration System\\Refined and Cleansed_Supply_Chain_Data.csv...\n",
      "‚úÖ Data read and preprocessed.\n",
      "‚ÑπÔ∏è Dataset 'Gold_Layer' already exists.\n",
      "üìä Grouping data by year and calculating aggregates...\n",
      "‚úÖ Table 'Agg_Yearly_Summary_Metrics' created.\n",
      "üöÄ Loading 5 rows into sharedproject2025.Gold_Layer.Agg_Yearly_Summary_Metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded data into sharedproject2025.Gold_Layer.Agg_Yearly_Summary_Metrics.\n",
      "---\n",
      "üìä Aggregating Product Performance...\n",
      "‚úÖ Table 'Agg_Product_Performance' created.\n",
      "üöÄ Loading 3610 rows into sharedproject2025.Gold_Layer.Agg_Product_Performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded data into sharedproject2025.Gold_Layer.Agg_Product_Performance.\n",
      "---\n",
      "üìä Aggregating Regional Segment Sales...\n",
      "‚úÖ Table 'Agg_Regional_Segment_Sales' created.\n",
      "üöÄ Loading 39 rows into sharedproject2025.Gold_Layer.Agg_Regional_Segment_Sales...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded data into sharedproject2025.Gold_Layer.Agg_Regional_Segment_Sales.\n",
      "---\n",
      "üìä Aggregating Monthly Financial Trends...\n",
      "‚úÖ Table 'Agg_Monthly_Financial_Trends' created.\n",
      "üöÄ Loading 48 rows into sharedproject2025.Gold_Layer.Agg_Monthly_Financial_Trends...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded data into sharedproject2025.Gold_Layer.Agg_Monthly_Financial_Trends.\n",
      "---\n",
      "\n",
      "üéâ All aggregation jobs done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.api_core.exceptions import Conflict\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ Authentication and Setup\n",
    "PROJECT_ID = \"sharedproject2025\"\n",
    "DATASET_ID = \"Gold_Layer\"\n",
    "CSV_PATH = r\"E:\\Supply Chain Data Integration System\\Refined and Cleansed_Supply_Chain_Data.csv\"\n",
    "key_path = r\"E:\\sharedproject2025-22cd4ce0c74f.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "# 2Ô∏è‚É£ Helper Function for BigQuery Loading\n",
    "def create_and_load_table(client, df, table_id, dataset_id):\n",
    "    \"\"\"\n",
    "    Creates a new table (if it doesn't exist) and loads a DataFrame into it,\n",
    "    truncating any existing data.\n",
    "    \"\"\"\n",
    "    table_ref_str = f\"{client.project}.{dataset_id}.{table_id}\"\n",
    "    table_ref = bigquery.Table(table_ref_str)\n",
    "\n",
    "    try:\n",
    "        client.create_table(table_ref)\n",
    "        print(f\"‚úÖ Table '{table_id}' created.\")\n",
    "    except Conflict:\n",
    "        print(f\"‚ÑπÔ∏è Table '{table_id}' already exists.\")\n",
    "\n",
    "    print(f\"üöÄ Loading {len(df)} rows into {table_ref_str}...\")\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        autodetect=True,\n",
    "        write_disposition=\"WRITE_TRUNCATE\"\n",
    "    )\n",
    "    job = client.load_table_from_dataframe(df, table_ref_str, job_config=job_config)\n",
    "    job.result()  # Wait for the job to complete\n",
    "    print(f\"‚úÖ Successfully loaded data into {table_ref_str}.\")\n",
    "    print(\"---\")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Data Preprocessing\n",
    "def load_and_preprocess(path):\n",
    "    print(f\"Reading data from {path}...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Convert to datetime (auto-detect format or assume day first)\n",
    "    df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True, errors='coerce')\n",
    "    df['Ship Date'] = pd.to_datetime(df['Ship Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "    # Time-based columns for trend analysis\n",
    "    df['order_year'] = df['Order Date'].dt.year\n",
    "    df['order_month'] = df['Order Date'].dt.to_period('M').dt.to_timestamp()\n",
    "    \n",
    "    # Handle potential div/0 errors\n",
    "    df['Sales'] = df['Sales'].replace({0: np.nan})\n",
    "    df['Quantity'] = df['Quantity'].replace({0: np.nan})\n",
    "\n",
    "    print(\"‚úÖ Data read and preprocessed.\")\n",
    "    return df\n",
    "\n",
    "# --- Read and Preprocess Data ---\n",
    "df = load_and_preprocess(CSV_PATH)\n",
    "\n",
    "# --- Create Dataset (if not exists) ---\n",
    "dataset_ref = bigquery.Dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\n",
    "try:\n",
    "    client.create_dataset(dataset_ref)\n",
    "    print(f\"‚úÖ Dataset '{DATASET_ID}' created.\")\n",
    "except Conflict:\n",
    "    print(f\"‚ÑπÔ∏è Dataset '{DATASET_ID}' already exists.\")\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ AGGREGATION 1: Yearly & Total Summary (Your Original Table)\n",
    "# -----------------------------------------------------------------\n",
    "print(\"üìä Grouping data by year and calculating aggregates...\")\n",
    "yearly_agg_df = df.groupby('order_year').agg(\n",
    "    Total_Sales=('Sales', 'sum'),\n",
    "    Total_Profit=('Profit', 'sum'),\n",
    "    Total_Units_Sold=('Quantity', 'sum'),\n",
    "    Total_Shipping_Cost=('Shipping_Cost', 'sum'),\n",
    "    Average_Discount=('Discount', 'mean'),\n",
    "    Average_Profit=('Profit', 'mean'),\n",
    "    Median_Profit=('Profit', 'median'),\n",
    "    Max_Profit=('Profit', 'max'),\n",
    "    Loss=('Profit', 'min'),\n",
    "    Average_Shipping_time_days=('Shipping_Duration_Days', 'mean')\n",
    ")\n",
    "\n",
    "total_agg = {\n",
    "    'Total_Sales': df['Sales'].sum(),\n",
    "    'Total_Profit': df['Profit'].sum(),\n",
    "    'Total_Units_Sold': df['Quantity'].sum(),\n",
    "    'Total_Shipping_Cost': df['Shipping_Cost'].sum(),\n",
    "    'Average_Discount': df['Discount'].mean(),\n",
    "    'Average_Profit': df['Profit'].mean(),\n",
    "    'Median_Profit': df['Profit'].median(),\n",
    "    'Max_Profit': df['Profit'].max(),\n",
    "    'Loss': df['Profit'].min(),\n",
    "    'Average_Shipping_time_days': df['Shipping_Duration_Days'].mean()\n",
    "}\n",
    "total_df = pd.DataFrame([total_agg], index=['All-Years Total'])\n",
    "\n",
    "combined_df = pd.concat([yearly_agg_df, total_df])\n",
    "combined_df = combined_df.reset_index().rename(columns={'index': 'Period'})\n",
    "\n",
    "combined_df['Profit_Margin'] = ((combined_df['Total_Profit'] / combined_df['Total_Sales'] * 100).fillna(0))\n",
    "combined_df['Average_Sales_Per_Unit'] = ((combined_df['Total_Sales'] / combined_df['Total_Units_Sold']).fillna(0))\n",
    "combined_df['Average_shipping_cost_per_unit'] = ((combined_df['Total_Shipping_Cost'] / combined_df['Total_Units_Sold']).fillna(0))\n",
    "combined_df['Total_Units_Sold'] = combined_df['Total_Units_Sold'].fillna(0).astype(int)\n",
    "combined_df = combined_df.round(2)\n",
    "combined_df[\"load_timestamp\"] = datetime.now()\n",
    "combined_df['Period'] = combined_df['Period'].astype(str) # Convert Period to string for BQ\n",
    "\n",
    "# --- Load Aggregation 1 ---\n",
    "create_and_load_table(client, combined_df, \"Agg_Yearly_Summary_Metrics\", DATASET_ID)\n",
    "\n",
    "\n",
    "# 5Ô∏è‚É£ AGGREGATION 2: Product Performance Summary\n",
    "# -----------------------------------------------------------------\n",
    "print(\"üìä Aggregating Product Performance...\")\n",
    "prod_agg_df = df.groupby(['Category', 'Sub-Category', 'Product Name']).agg(\n",
    "    Total_Sales=('Sales', 'sum'),\n",
    "    Total_Profit=('Profit', 'sum'),\n",
    "    Total_Quantity=('Quantity', 'sum'),\n",
    "    Average_Discount=('Discount', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "prod_agg_df['Profit_Margin'] = ((prod_agg_df['Total_Profit'] / prod_agg_df['Total_Sales'] * 100).fillna(0))\n",
    "prod_agg_df = prod_agg_df.round(2)\n",
    "prod_agg_df[\"load_timestamp\"] = datetime.now()\n",
    "\n",
    "# --- Load Aggregation 2 ---\n",
    "create_and_load_table(client, prod_agg_df, \"Agg_Product_Performance\", DATASET_ID)\n",
    "\n",
    "\n",
    "# 6Ô∏è‚É£ AGGREGATION 3: Regional Segment Sales\n",
    "# -----------------------------------------------------------------\n",
    "print(\"üìä Aggregating Regional Segment Sales...\")\n",
    "region_seg_df = df.groupby(['Region', 'Segment']).agg(\n",
    "    Total_Sales=('Sales', 'sum'),\n",
    "    Total_Profit=('Profit', 'sum'),\n",
    "    Total_Quantity=('Quantity', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "region_seg_df['Profit_Margin'] = ((region_seg_df['Total_Profit'] / region_seg_df['Total_Sales'] * 100).fillna(0))\n",
    "region_seg_df = region_seg_df.round(2)\n",
    "region_seg_df[\"load_timestamp\"] = datetime.now()\n",
    "\n",
    "# --- Load Aggregation 3 ---\n",
    "create_and_load_table(client, region_seg_df, \"Agg_Regional_Segment_Sales\", DATASET_ID)\n",
    "\n",
    "\n",
    "# 7Ô∏è‚É£ AGGREGATION 4: Monthly Financial Trends\n",
    "# -----------------------------------------------------------------\n",
    "print(\"üìä Aggregating Monthly Financial Trends...\")\n",
    "monthly_df = df.groupby('order_month').agg(\n",
    "    Total_Sales=('Sales', 'sum'),\n",
    "    Total_Profit=('Profit', 'sum'),\n",
    "    Total_Quantity=('Quantity', 'sum'),\n",
    "    Total_Orders=('Order ID', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "monthly_df = monthly_df.round(2)\n",
    "# Convert timestamp to string for BQ compatibility\n",
    "monthly_df['order_month'] = monthly_df['order_month'].astype(str)\n",
    "monthly_df[\"load_timestamp\"] = datetime.now()\n",
    "\n",
    "# --- Load Aggregation 4 ---\n",
    "create_and_load_table(client, monthly_df, \"Agg_Monthly_Financial_Trends\", DATASET_ID)\n",
    "\n",
    "\n",
    "print(\"\\nüéâ All aggregation jobs done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
