{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c298f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: module 'importlib.metadata' has no attribute 'packages_distributions'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\api_core\\_python_version_support.py:252: FutureWarning: You are using a Python version (3.9.13) past its end of life. Google will update google.api_core with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Extracting data from CSV...\n",
      "‚úÖ Data extracted. Sample:\n",
      "          Order ID  Order Date   Ship Date     Ship Mode Customer ID  \\\n",
      "0   CA-2012-124891  31-07-2012  31-07-2012      Same Day    RH-19495   \n",
      "1    IN-2013-77878  05-02-2013  07-02-2013  Second Class    JR-16210   \n",
      "2    IN-2013-71249  17-10-2013  18-10-2013   First Class    CR-12730   \n",
      "3  ES-2013-1579342  28-01-2013  30-01-2013   First Class    KM-16375   \n",
      "4     SG-2013-4320  05-11-2013  06-11-2013      Same Day     RH-9495   \n",
      "\n",
      "      Customer Name      Segment           City            State  \\\n",
      "0       Rick Hansen     Consumer  new york city         New York   \n",
      "1     Justin Ritter    Corporate     wollongong  New South Wales   \n",
      "2      Craig Reiter     Consumer       brisbane       Queensland   \n",
      "3  Katherine Murray  Home Office         berlin           Berlin   \n",
      "4       Rick Hansen     Consumer          dakar            Dakar   \n",
      "\n",
      "         Country  ... Sub-Category  \\\n",
      "0  United States  ...  Accessories   \n",
      "1      Australia  ...       Chairs   \n",
      "2      Australia  ...       Phones   \n",
      "3        Germany  ...       Phones   \n",
      "4        Senegal  ...      Copiers   \n",
      "\n",
      "                                        Product Name     Sales Quantity  \\\n",
      "0  Plantronics CS510 - Over-the-Head monaural Wir...  2309.650        7   \n",
      "1          Novimex Executive Leather Armchair, Black  3709.395        9   \n",
      "2                  Nokia Smart Phone, with Caller ID  5175.171        9   \n",
      "3                     Motorola Smart Phone, Cordless  2892.510        5   \n",
      "4                     Sharp Wireless Fax, High-Speed  2832.960        8   \n",
      "\n",
      "  Discount    Profit Shipping Cost  Order Priority  \\\n",
      "0      0.0  762.1845        933.57        Critical   \n",
      "1      0.1 -288.7650        923.63        Critical   \n",
      "2      0.1  919.9710        915.49          Medium   \n",
      "3      0.1  -96.5400        910.16          Medium   \n",
      "4      0.0  311.5200        903.04        Critical   \n",
      "\n",
      "               load_timestamp  Shipping_Duration_Days  \n",
      "0  2025-11-05 10:01:41.054278                       0  \n",
      "1  2025-11-05 10:01:41.054278                       2  \n",
      "2  2025-11-05 10:01:41.054278                       1  \n",
      "3  2025-11-05 10:01:41.054278                       2  \n",
      "4  2025-11-05 10:01:41.054278                       1  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "‚ÑπÔ∏è Dataset 'Silver_Layer' already exists.\n",
      "‚ÑπÔ∏è Table 'Cleansed_Supply_Chain_Data' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded 25035 rows into trim-plexus-396409.Silver_Layer.Cleansed_Supply_Chain_Data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.api_core.exceptions import Conflict\n",
    "\n",
    "# 1Ô∏è‚É£ Authentication and Setup\n",
    "\n",
    "PROJECT_ID = \"trim-plexus-396409\"\n",
    "DATASET_ID = \"Bronze_Layer\"\n",
    "TABLE_ID = \"Raw_Supply_Chain_Data\"\n",
    "CSV_PATH = r\"E:\\Supply Chain Data Integration System\\Global_Superstore.csv\"\n",
    "\n",
    "key_path = r\"E:\\BigQueryAssignment\\trim-plexus-396409-dfc55c39f51e.json\"  # change this path\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "# 2Ô∏è‚É£ Extract: Read CSV file into pandas\n",
    "print(\"üì• Extracting data from CSV...\")\n",
    "df = pd.read_csv(CSV_PATH, encoding='latin1')\n",
    "\n",
    "print(\"‚úÖ Data extracted. Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "# 4Ô∏è‚É£ Load: Create dataset and table in BigQuery if not exists\n",
    "dataset_ref = bigquery.Dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\n",
    "dataset_ref.location = \"US\"\n",
    "\n",
    "try:\n",
    "    client.create_dataset(dataset_ref)\n",
    "    print(f\"‚úÖ Dataset '{DATASET_ID}' created.\")\n",
    "except Conflict:\n",
    "    print(f\"‚ÑπÔ∏è Dataset '{DATASET_ID}' already exists.\")\n",
    "\n",
    "table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "table = bigquery.Table(table_ref)\n",
    "\n",
    "try:\n",
    "    client.create_table(table)\n",
    "    print(f\"‚úÖ Table '{TABLE_ID}' created.\")\n",
    "except Conflict:\n",
    "    print(f\"‚ÑπÔ∏è Table '{TABLE_ID}' already exists.\")\n",
    "\n",
    "\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True, \n",
    "    # Specify the source format. Common formats include CSV, NEWLINE_DELIMITED_JSON, AVRO.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    write_disposition=\"WRITE_TRUNCATE\"  # Replace table data\n",
    "    \n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded {len(df)} rows into {table_ref}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
